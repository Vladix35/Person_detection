{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fed41527",
   "metadata": {},
   "source": [
    "# ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a77a0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.223 ğŸš€ Python-3.9.23 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 5805MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco8.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/vladix35/programming/pet_projects/person_detector/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    850368  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
      "YOLO11s summary: 181 layers, 9,458,752 parameters, 9,458,736 gradients, 21.7 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2089.3Â±748.7 MB/s, size: 50.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/vladix35/programming/pet_projects/object_detection/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 11.1Kit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1075.4Â±555.3 MB/s, size: 54.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/vladix35/programming/pet_projects/object_detection/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.1Kit/s 0.0s0s\n",
      "Plotting labels to /home/vladix35/programming/pet_projects/person_detector/runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/vladix35/programming/pet_projects/person_detector/runs/detect/train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      1.13G     0.9194      2.882      1.268         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 0.3it/s 2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1it/s 0.9s\n",
      "                   all          4         17      0.927      0.791      0.932       0.74\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      1.14G      1.134      2.774      1.441         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.9it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.8it/s 0.1s\n",
      "                   all          4         17      0.929      0.793       0.93       0.74\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100      1.16G      1.387      3.805       1.64         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.5it/s 0.1s\n",
      "                   all          4         17      0.927      0.795      0.932       0.74\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      1.18G      0.907      2.464      1.216         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.0it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.1it/s 0.1s\n",
      "                   all          4         17      0.925      0.797      0.933      0.737\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      1.29G       1.34      2.329      1.646         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.9it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.4it/s 0.1s\n",
      "                   all          4         17      0.924      0.798       0.93      0.735\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      1.36G     0.9016      1.767      1.301         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.6it/s 0.1s\n",
      "                   all          4         17      0.912      0.801      0.929      0.743\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100       1.4G       1.38      2.895      1.585         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.9it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.7it/s 0.1s\n",
      "                   all          4         17      0.906      0.803      0.929      0.727\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100       1.4G      1.408      4.227      1.793         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.7it/s 0.0s\n",
      "                   all          4         17       0.87       0.86      0.955      0.737\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100       1.4G      1.189      2.378      1.359         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.2it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.5it/s 0.0s\n",
      "                   all          4         17      0.871      0.852      0.955      0.737\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100       1.4G      1.216      2.017      1.561         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.6it/s 0.0s\n",
      "                   all          4         17       0.88      0.846      0.955      0.735\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100       1.4G      1.018      1.385      1.346         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.5it/s 0.0s\n",
      "                   all          4         17      0.853      0.867      0.956      0.738\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      1.46G      1.008      2.146      1.297         44        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.0it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.4it/s 0.0s\n",
      "                   all          4         17      0.796       0.88      0.959       0.73\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      1.52G     0.8799      2.151      1.233         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.2it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.6it/s 0.0s\n",
      "                   all          4         17      0.878      0.843      0.959      0.662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      1.56G      1.059      1.373       1.35         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.9it/s 0.0s\n",
      "                   all          4         17      0.862      0.852      0.955      0.669\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      1.62G      1.261      1.785      1.481         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.2it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.0it/s 0.0s\n",
      "                   all          4         17      0.848      0.876      0.957       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      1.62G     0.8995      1.566      1.289         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.2it/s 0.0s\n",
      "                   all          4         17      0.838      0.887      0.956      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      1.62G     0.8318      2.044      1.284         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.0it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.9it/s 0.0s\n",
      "                   all          4         17      0.839      0.891      0.956      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      1.62G     0.8454      1.455      1.187         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.8it/s 0.0s\n",
      "                   all          4         17      0.839      0.891      0.956      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      1.62G     0.9799      1.208      1.406         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.6it/s 0.1s\n",
      "                   all          4         17      0.839      0.894      0.955      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      1.62G      1.052        1.8      1.362         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.6it/s 0.1s\n",
      "                   all          4         17      0.839      0.894      0.955      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      1.62G     0.9716      1.181      1.433         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.5it/s 0.0s\n",
      "                   all          4         17      0.848      0.897      0.956      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      1.62G     0.9966       1.73      1.411         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.8it/s 0.0s\n",
      "                   all          4         17      0.848      0.897      0.956      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100      1.62G     0.9048      1.258      1.333         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.4it/s 0.1s\n",
      "                   all          4         17      0.855      0.897      0.955      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      1.62G     0.5804     0.7136      1.118         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.7it/s 0.1s\n",
      "                   all          4         17      0.855      0.897      0.955      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      1.62G     0.5475      1.138      1.007         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.5it/s 0.1s\n",
      "                   all          4         17      0.772      0.917      0.926      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      1.62G     0.7641      1.008      1.156         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.6it/s 0.1s\n",
      "                   all          4         17      0.772      0.917      0.926      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      1.62G     0.7531      1.109      1.154         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.9it/s 0.1s\n",
      "                   all          4         17      0.775      0.917      0.927      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100      1.62G     0.9591      0.951      1.233         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.8it/s 0.1s\n",
      "                   all          4         17      0.775      0.917      0.927      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      1.62G     0.9089     0.9288      1.343         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.7it/s 0.1s\n",
      "                   all          4         17      0.778      0.917      0.927      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      1.62G     0.7323     0.9262      1.363         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.8it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.3it/s 0.0s\n",
      "                   all          4         17      0.778      0.917      0.927      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      1.62G     0.9019     0.8973      1.351         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 17.9it/s 0.1s\n",
      "                   all          4         17      0.792       0.92      0.929      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100      1.62G     0.6642      0.886      1.157         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.6it/s 0.1s\n",
      "                   all          4         17      0.792       0.92      0.929      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100      1.62G     0.6664     0.6375      1.136         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.7it/s 0.1s\n",
      "                   all          4         17      0.896      0.881      0.954      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100      1.62G      1.026     0.7581      1.226         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.9it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.3it/s 0.0s\n",
      "                   all          4         17      0.896      0.881      0.954      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      1.62G     0.6583     0.6487       1.03         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.7it/s 0.1s\n",
      "                   all          4         17      0.811      0.921      0.956        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100      1.62G     0.6004     0.7251      1.132         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.6it/s 0.1s\n",
      "                   all          4         17      0.811      0.921      0.956        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100      1.62G      0.915     0.8095      1.402         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.2it/s 0.1s\n",
      "                   all          4         17      0.781      0.926      0.929      0.601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100      1.62G     0.7047     0.7207      1.065         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.7it/s 0.1s\n",
      "                   all          4         17      0.781      0.926      0.929      0.601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100      1.62G     0.4225     0.5023     0.8864         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.8it/s 0.1s\n",
      "                   all          4         17      0.714      0.933      0.929      0.583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100      1.62G     0.7988     0.6875      1.167         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.9it/s 0.1s\n",
      "                   all          4         17      0.714      0.933      0.929      0.583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      1.62G     0.6338     0.5708      1.036         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.1it/s 0.0s\n",
      "                   all          4         17      0.621      0.964       0.93      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      1.62G     0.6406     0.6696      1.016         46        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.0it/s 0.0s\n",
      "                   all          4         17      0.621      0.964       0.93      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100      1.62G     0.3955     0.8318     0.9921         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.3it/s 0.1s\n",
      "                   all          4         17      0.669      0.963       0.93      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      1.62G     0.7849      1.136       1.16         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 17.9it/s 0.1s\n",
      "                   all          4         17      0.669      0.963       0.93      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100      1.62G     0.5855     0.7528       1.14         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.2it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.4it/s 0.1s\n",
      "                   all          4         17      0.662      0.598      0.766      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      1.62G     0.6753      0.944      1.108         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.2it/s 0.1s\n",
      "                   all          4         17      0.662      0.598      0.766      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100      1.62G     0.7936     0.8468      1.129         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.8it/s 0.1s\n",
      "                   all          4         17      0.661      0.597      0.758      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      1.62G     0.7329     0.4559      1.174         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.2it/s 0.1s\n",
      "                   all          4         17      0.661      0.597      0.758      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100      1.62G     0.5511     0.6362      1.061         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.0it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.6it/s 0.1s\n",
      "                   all          4         17       0.66      0.597      0.758      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      1.62G     0.5812      0.544      1.063         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.7it/s 0.1s\n",
      "                   all          4         17       0.66      0.597      0.758      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      1.62G      0.686      0.513      1.075         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.2it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 22.3it/s 0.0s\n",
      "                   all          4         17      0.661      0.598      0.758      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      1.62G     0.6144     0.7595     0.9867         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.5it/s 0.0s\n",
      "                   all          4         17      0.661      0.598      0.758      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100      1.62G     0.5147     0.5153     0.9807         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.9it/s 0.0s\n",
      "                   all          4         17      0.661      0.598      0.758      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      1.62G     0.5239     0.4465      1.116         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.2it/s 0.1s\n",
      "                   all          4         17      0.659      0.594      0.758      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100      1.62G     0.4819     0.7079     0.9846         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.5it/s 0.1s\n",
      "                   all          4         17      0.659      0.594      0.758      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      1.62G     0.6565     0.5829      1.212         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.9it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.5it/s 0.1s\n",
      "                   all          4         17      0.659      0.594      0.758      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      1.62G     0.6244     0.4319      1.023         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.1it/s 0.0s\n",
      "                   all          4         17      0.822      0.598      0.766      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      1.62G     0.6282     0.4204      1.124         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.0it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.3it/s 0.1s\n",
      "                   all          4         17      0.822      0.598      0.766      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      1.62G     0.5898      0.434      0.949         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.9it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.8it/s 0.1s\n",
      "                   all          4         17      0.822      0.598      0.766      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      1.62G      0.721     0.6366      1.131         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.6it/s 0.1s\n",
      "                   all          4         17      0.825      0.592      0.766      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      1.62G     0.4812     0.4902     0.8607         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.2it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.6it/s 0.1s\n",
      "                   all          4         17      0.825      0.592      0.766      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      1.62G     0.4645     0.3991     0.8936         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.9it/s 0.1s\n",
      "                   all          4         17      0.825      0.592      0.766      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100      1.62G     0.6964     0.7081      1.183         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.4it/s 0.1s\n",
      "                   all          4         17      0.824      0.592      0.764      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      1.62G     0.6602      0.544      1.148         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.2it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.9it/s 0.1s\n",
      "                   all          4         17      0.824      0.592      0.764      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      1.62G     0.4585     0.4336     0.9597         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.4it/s 0.1s\n",
      "                   all          4         17      0.824      0.592      0.764      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      1.62G     0.5488     0.6607      1.009         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.6it/s 0.1s\n",
      "                   all          4         17      0.822       0.59      0.764      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      1.62G     0.6881     0.6055      1.133         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.9it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.0it/s 0.1s\n",
      "                   all          4         17      0.822       0.59      0.764      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      1.62G     0.4899     0.5373     0.9702         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.6it/s 0.1s\n",
      "                   all          4         17      0.822       0.59      0.764      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      1.62G     0.5543     0.4089     0.9894         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.8it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.2it/s 0.1s\n",
      "                   all          4         17      0.793      0.569      0.759      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      1.62G     0.4715     0.4806     0.9232         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.7it/s 0.1s\n",
      "                   all          4         17      0.793      0.569      0.759      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100      1.62G     0.5399     0.3651      1.016         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.0it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.6it/s 0.1s\n",
      "                   all          4         17      0.793      0.569      0.759      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      1.62G     0.4647     0.5285      1.036         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.5it/s 0.1s\n",
      "                   all          4         17      0.825      0.592      0.766      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100      1.62G      0.515     0.4554      0.996         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.1it/s 0.1s\n",
      "                   all          4         17      0.825      0.592      0.766      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      1.62G     0.4864     0.4132      1.062         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.0it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.7it/s 0.1s\n",
      "                   all          4         17      0.825      0.592      0.766      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100      1.62G     0.5012     0.4933     0.9536         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.8it/s 0.1s\n",
      "                   all          4         17      0.793      0.576      0.737      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100      1.62G     0.4973     0.3761     0.9589         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.9it/s 0.0s\n",
      "                   all          4         17      0.793      0.576      0.737      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      1.62G     0.5471     0.6911      1.014         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.0it/s 0.0s\n",
      "                   all          4         17      0.793      0.576      0.737      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100      1.62G     0.6532     0.4613      1.137         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.9it/s 0.1s\n",
      "                   all          4         17      0.792      0.575      0.736      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100      1.62G     0.4989     0.5033      1.044         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.0it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.4it/s 0.1s\n",
      "                   all          4         17      0.792      0.575      0.736      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      1.62G     0.5375     0.3954     0.9292         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.0it/s 0.1s\n",
      "                   all          4         17      0.792      0.575      0.736      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      1.62G     0.4251     0.5426      1.003         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.9it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.8it/s 0.0s\n",
      "                   all          4         17      0.793      0.571      0.736      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      1.62G     0.5157     0.4452      1.079         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.7it/s 0.1s\n",
      "                   all          4         17      0.793      0.571      0.736      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100      1.62G     0.4832     0.5282      1.093         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.8it/s 0.0s\n",
      "                   all          4         17      0.793      0.571      0.736      0.541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      1.62G     0.5091     0.4153     0.9861         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.0it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.3it/s 0.1s\n",
      "                   all          4         17      0.791      0.572      0.738      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      1.62G     0.5311     0.4985      1.054         51        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.9it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 22.0it/s 0.0s\n",
      "                   all          4         17      0.791      0.572      0.738      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      1.62G      0.511     0.6165      1.014         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.1it/s 0.1s\n",
      "                   all          4         17      0.791      0.572      0.738      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      1.62G     0.9315     0.9657      1.408         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.8it/s 0.1s\n",
      "                   all          4         17      0.791      0.572      0.738      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      1.62G     0.4171     0.6023     0.9634         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.1it/s 0.1s\n",
      "                   all          4         17       0.79      0.566      0.736      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      1.62G     0.4434     0.6613      1.125         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.0it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.2it/s 0.1s\n",
      "                   all          4         17       0.79      0.566      0.736      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      1.62G     0.7162     0.6049      1.179         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.5it/s 0.0s\n",
      "                   all          4         17       0.79      0.566      0.736      0.526\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      1.62G     0.4931     0.3536      1.025         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.7it/s 0.1s\n",
      "                   all          4         17       0.79      0.566      0.736      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      1.62G     0.4565     0.3164      1.041         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.4it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.2it/s 0.1s\n",
      "                   all          4         17      0.588        0.6      0.737      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100      1.62G     0.3488     0.3139     0.8356         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.2it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.2it/s 0.0s\n",
      "                   all          4         17      0.588        0.6      0.737      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100      1.62G     0.4563     0.3591     0.8748         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 20.7it/s 0.0s\n",
      "                   all          4         17      0.588        0.6      0.737      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100      1.62G     0.4238     0.3679     0.9237         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 19.5it/s 0.1s\n",
      "                   all          4         17      0.588        0.6      0.737      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100      1.62G     0.3198     0.2969     0.8611         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 17.7it/s 0.1s\n",
      "                   all          4         17      0.591      0.748      0.734      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      1.62G     0.4166     0.3097      0.923         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 18.8it/s 0.1s\n",
      "                   all          4         17      0.591      0.748      0.734      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100      1.62G     0.3545     0.3164     0.8634         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 17.9it/s 0.1s\n",
      "                   all          4         17      0.591      0.748      0.734      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100      1.62G     0.4273     0.4519     0.9781         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.6it/s 0.0s\n",
      "                   all          4         17      0.591      0.748      0.734      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100      1.62G      0.332     0.2775     0.8498         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 21.2it/s 0.0s\n",
      "                   all          4         17      0.649      0.745      0.767      0.539\n",
      "\n",
      "100 epochs completed in 0.016 hours.\n",
      "Optimizer stripped from /home/vladix35/programming/pet_projects/person_detector/runs/detect/train/weights/last.pt, 19.2MB\n",
      "Optimizer stripped from /home/vladix35/programming/pet_projects/person_detector/runs/detect/train/weights/best.pt, 19.2MB\n",
      "\n",
      "Validating /home/vladix35/programming/pet_projects/person_detector/runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.223 ğŸš€ Python-3.9.23 torch-2.8.0+cu129 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 5805MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,443,760 parameters, 0 gradients, 21.5 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 17.8it/s 0.1s\n",
      "                   all          4         17      0.914        0.8      0.929      0.739\n",
      "                person          3         10          1      0.302      0.768      0.419\n",
      "                   dog          1          1      0.945          1      0.995      0.895\n",
      "                 horse          1          2      0.918          1      0.995      0.699\n",
      "              elephant          1          2      0.924        0.5      0.828      0.532\n",
      "              umbrella          1          1      0.815          1      0.995      0.995\n",
      "          potted plant          1          1      0.885          1      0.995      0.895\n",
      "Speed: 0.3ms preprocess, 6.9ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/vladix35/programming/pet_projects/person_detector/runs/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"coco8.yaml\", epochs=100, imgsz=640)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf695fd",
   "metadata": {},
   "source": [
    "# Ğ˜Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57daba18",
   "metadata": {},
   "source": [
    "## Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ»ÑĞ´ĞµĞ¹:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e0f616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11s summary (fused): 100 layers, 9,443,760 parameters, 0 gradients, 21.5 GFLOPs\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 10.0ms\n",
      "Speed: 18.4ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 8.9ms\n",
      "Speed: 1.9ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.8ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.6ms\n",
      "Speed: 1.9ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 2.1ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.5ms\n",
      "Speed: 1.8ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 1 bird, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 1 bird, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 dining table, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.3ms\n",
      "Speed: 2.0ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 dining table, 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 dining table, 7.8ms\n",
      "Speed: 2.4ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 dining table, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 dining table, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 dining table, 8.3ms\n",
      "Speed: 2.1ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 dining table, 19.0ms\n",
      "Speed: 1.9ms preprocess, 19.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.8ms\n",
      "Speed: 2.0ms preprocess, 7.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.9ms\n",
      "Speed: 2.1ms preprocess, 7.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.3ms\n",
      "Speed: 2.1ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 2 chairs, 1 dining table, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.4ms\n",
      "Speed: 2.0ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.9ms\n",
      "Speed: 2.1ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 7.4ms\n",
      "Speed: 1.9ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 stop sign, 2 umbrellas, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.9ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 1 backpack, 2 umbrellas, 1 dining table, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 1 backpack, 2 umbrellas, 1 dining table, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 stop sign, 1 backpack, 2 umbrellas, 1 dining table, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 1 backpack, 2 umbrellas, 1 dining table, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 1 backpack, 2 umbrellas, 1 dining table, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 1 backpack, 2 umbrellas, 1 dining table, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 2 umbrellas, 1 dining table, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 dining table, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 2.1ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 umbrellas, 1 chair, 1 dining table, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 2 umbrellas, 1 dining table, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 2 umbrellas, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 2 umbrellas, 1 dining table, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 2 umbrellas, 1 chair, 1 dining table, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 2 umbrellas, 2 chairs, 1 dining table, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 2 umbrellas, 1 bottle, 1 chair, 1 dining table, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 2 umbrellas, 1 bottle, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 bottle, 1 dining table, 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 bottle, 1 dining table, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 bottle, 1 dining table, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 2 umbrellas, 1 dining table, 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 2 umbrellas, 1 chair, 1 dining table, 7.5ms\n",
      "Speed: 1.8ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 1 chair, 1 dining table, 8.2ms\n",
      "Speed: 1.8ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 dining table, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 dining table, 7.0ms\n",
      "Speed: 2.1ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 dining table, 6.6ms\n",
      "Speed: 2.0ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 2 umbrellas, 1 dining table, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 backpack, 2 umbrellas, 1 dining table, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 umbrellas, 1 dining table, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 umbrellas, 1 dining table, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 8.2ms\n",
      "Speed: 2.2ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.6ms\n",
      "Speed: 1.6ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 handbag, 1 dining table, 7.9ms\n",
      "Speed: 2.1ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.2ms\n",
      "Speed: 2.3ms preprocess, 7.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 6.6ms\n",
      "Speed: 1.9ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 donut, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 donut, 1 chair, 1 dining table, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.9ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 7.7ms\n",
      "Speed: 1.9ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 2 chairs, 1 dining table, 7.1ms\n",
      "Speed: 1.8ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 2 chairs, 1 dining table, 19.4ms\n",
      "Speed: 2.0ms preprocess, 19.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 2 chairs, 1 dining table, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 2 chairs, 1 dining table, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 2 chairs, 1 dining table, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 2 chairs, 1 dining table, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.4ms\n",
      "Speed: 1.9ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 6.6ms\n",
      "Speed: 1.8ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 6.9ms\n",
      "Speed: 2.2ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 chair, 1 dining table, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 chair, 1 dining table, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 1 chair, 1 dining table, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 7.9ms\n",
      "Speed: 1.9ms preprocess, 7.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 1 backpack, 2 umbrellas, 3 handbags, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.2ms\n",
      "Speed: 1.9ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 backpacks, 2 umbrellas, 3 handbags, 1 chair, 1 dining table, 7.6ms\n",
      "Speed: 1.6ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 3 backpacks, 2 umbrellas, 1 handbag, 1 chair, 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 3 backpacks, 2 umbrellas, 4 handbags, 2 chairs, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 3 backpacks, 2 umbrellas, 1 handbag, 1 chair, 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 3 backpacks, 2 umbrellas, 1 handbag, 1 chair, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 3 backpacks, 2 umbrellas, 1 handbag, 1 chair, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 stop sign, 3 backpacks, 2 umbrellas, 2 handbags, 1 chair, 7.3ms\n",
      "Speed: 2.2ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 stop sign, 3 backpacks, 2 umbrellas, 2 handbags, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 3 backpacks, 2 umbrellas, 3 handbags, 7.3ms\n",
      "Speed: 1.9ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 3 backpacks, 2 umbrellas, 1 handbag, 7.4ms\n",
      "Speed: 2.5ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 3 backpacks, 2 umbrellas, 2 handbags, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 backpacks, 2 umbrellas, 1 handbag, 7.5ms\n",
      "Speed: 1.8ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 backpacks, 2 umbrellas, 2 handbags, 1 donut, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 backpacks, 2 umbrellas, 1 handbag, 1 donut, 1 chair, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 backpacks, 2 umbrellas, 1 handbag, 1 donut, 1 chair, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 backpacks, 2 umbrellas, 2 handbags, 1 donut, 7.7ms\n",
      "Speed: 2.2ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 3 backpacks, 2 umbrellas, 1 donut, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 3 backpacks, 2 umbrellas, 2 handbags, 1 donut, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 3 backpacks, 2 umbrellas, 1 handbag, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 3 backpacks, 2 umbrellas, 1 handbag, 7.9ms\n",
      "Speed: 2.5ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 backpacks, 2 umbrellas, 1 handbag, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 backpacks, 2 umbrellas, 1 handbag, 1 tv, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 3 backpacks, 2 umbrellas, 1 handbag, 1 donut, 1 tv, 7.7ms\n",
      "Speed: 2.2ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 1 donut, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 donut, 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 donut, 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 donut, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 3 handbags, 1 donut, 1 tv, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 donut, 1 tv, 8.5ms\n",
      "Speed: 2.1ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 donut, 1 dining table, 1 tv, 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 donut, 1 tv, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 backpack, 2 umbrellas, 2 handbags, 1 donut, 8.0ms\n",
      "Speed: 1.9ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 backpack, 2 umbrellas, 1 handbag, 1 donut, 1 dining table, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 1 handbag, 1 donut, 1 chair, 1 dining table, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 3 handbags, 1 chair, 1 dining table, 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 3 handbags, 1 donut, 1 dining table, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 1 handbag, 1 dining table, 7.6ms\n",
      "Speed: 2.2ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 7.9ms\n",
      "Speed: 2.4ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 2 umbrellas, 4 handbags, 1 dining table, 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 8.4ms\n",
      "Speed: 1.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 backpacks, 2 umbrellas, 1 dining table, 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 2 umbrellas, 1 handbag, 1 dining table, 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 1 handbag, 1 dining table, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 2 handbags, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 2 handbags, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 4 handbags, 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 3 handbags, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 3 handbags, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 motorcycle, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 motorcycle, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 1 handbag, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 2 umbrellas, 1 handbag, 7.8ms\n",
      "Speed: 1.8ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 banana, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 3 umbrellas, 1 handbag, 1 banana, 8.2ms\n",
      "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 3 umbrellas, 1 handbag, 1 banana, 8.1ms\n",
      "Speed: 1.9ms preprocess, 8.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 2 umbrellas, 1 handbag, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 donut, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 2 handbags, 2 donuts, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 umbrellas, 3 handbags, 7.1ms\n",
      "Speed: 1.8ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 2 umbrellas, 2 handbags, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 2 umbrellas, 2 handbags, 7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 2 umbrellas, 3 handbags, 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 backpack, 2 umbrellas, 3 handbags, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 2 umbrellas, 2 handbags, 7.7ms\n",
      "Speed: 1.9ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 3 backpacks, 2 umbrellas, 1 handbag, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 3 backpacks, 2 umbrellas, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 backpacks, 2 umbrellas, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 8.3ms\n",
      "Speed: 1.8ms preprocess, 8.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 2 handbags, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 2 handbags, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 2 handbags, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 2 handbags, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 tv, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 3 handbags, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 3 handbags, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 2 handbags, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 3 backpacks, 2 umbrellas, 4 handbags, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 5 handbags, 1 donut, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 3 handbags, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 3 handbags, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 umbrella, 3 handbags, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 1 umbrella, 3 handbags, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 stop sign, 1 backpack, 1 umbrella, 2 handbags, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 umbrellas, 2 handbags, 2 donuts, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 2 donuts, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 umbrellas, 1 handbag, 2 donuts, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 1 handbag, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 stop sign, 2 backpacks, 2 umbrellas, 2 handbags, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 backpacks, 2 umbrellas, 2 handbags, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 2 umbrellas, 2 handbags, 7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 2 handbags, 9.4ms\n",
      "Speed: 4.7ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 1 handbag, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 3 backpacks, 2 umbrellas, 2 handbags, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 3 backpacks, 2 umbrellas, 3 handbags, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 8.5ms\n",
      "Speed: 1.9ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 donut, 1 chair, 8.3ms\n",
      "Speed: 2.0ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 2 handbags, 3 donuts, 1 chair, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 2 umbrellas, 2 handbags, 4 donuts, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 2 handbags, 4 donuts, 1 chair, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 2 handbags, 2 donuts, 1 chair, 8.7ms\n",
      "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 donut, 1 dining table, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 3 handbags, 1 donut, 1 dining table, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 1 backpack, 2 umbrellas, 3 handbags, 1 donut, 1 dining table, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 2 handbags, 1 dining table, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 2 handbags, 1 banana, 1 dining table, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 2 umbrellas, 2 handbags, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 bus, 1 stop sign, 2 backpacks, 2 umbrellas, 2 handbags, 1 donut, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 bus, 1 stop sign, 2 backpacks, 2 umbrellas, 2 handbags, 1 donut, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 bus, 2 backpacks, 2 umbrellas, 2 handbags, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 2 handbags, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 3 backpacks, 2 umbrellas, 2 handbags, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 2 backpacks, 2 umbrellas, 2 handbags, 7.7ms\n",
      "Speed: 2.0ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 3 backpacks, 2 umbrellas, 3 handbags, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 backpacks, 2 umbrellas, 3 handbags, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 2 umbrellas, 3 handbags, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 2 umbrellas, 4 handbags, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 umbrella, 3 handbags, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 3 handbags, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 3 backpacks, 2 umbrellas, 4 handbags, 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 3 handbags, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 1 handbag, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 8.1ms\n",
      "Speed: 1.9ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 3 handbags, 8.6ms\n",
      "Speed: 1.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 7.6ms\n",
      "Speed: 1.6ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 2 umbrellas, 3 handbags, 7.7ms\n",
      "Speed: 1.9ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 2 umbrellas, 3 handbags, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 3 handbags, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 2 umbrellas, 3 handbags, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 3 handbags, 7.7ms\n",
      "Speed: 2.0ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 1 handbag, 7.9ms\n",
      "Speed: 1.9ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 2 umbrellas, 1 handbag, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 2 umbrellas, 2 handbags, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 3 backpacks, 2 umbrellas, 3 handbags, 1 dining table, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 handbag, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 2 handbags, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 backpacks, 2 umbrellas, 2 handbags, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 1 handbag, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 1 handbag, 8.2ms\n",
      "Speed: 2.3ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 backpacks, 2 umbrellas, 1 handbag, 1 dining table, 15.9ms\n",
      "Speed: 1.9ms preprocess, 15.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 3 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 3 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 3 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 7.5ms\n",
      "Speed: 1.7ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 3 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 donut, 1 dining table, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 backpacks, 2 umbrellas, 2 handbags, 1 donut, 1 dining table, 9.2ms\n",
      "Speed: 2.1ms preprocess, 9.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 3 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.8ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 backpacks, 2 umbrellas, 4 handbags, 1 dining table, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 backpacks, 2 umbrellas, 4 handbags, 1 dining table, 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.8ms\n",
      "Speed: 2.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.3ms\n",
      "Speed: 2.1ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 2 umbrellas, 1 handbag, 1 dining table, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 1 handbag, 1 dining table, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 3 handbags, 1 dining table, 8.7ms\n",
      "Speed: 1.8ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 3 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 8.2ms\n",
      "Speed: 2.1ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.9ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 backpacks, 2 umbrellas, 1 dining table, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 backpacks, 2 umbrellas, 1 handbag, 1 dining table, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 4 handbags, 1 dining table, 7.5ms\n",
      "Speed: 2.4ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 7.2ms\n",
      "Speed: 1.7ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 2 umbrellas, 2 handbags, 1 dining table, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.2ms\n",
      "Speed: 2.1ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 dining table, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 7.7ms\n",
      "Speed: 1.9ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 1 stop sign, 2 umbrellas, 1 handbag, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 2 umbrellas, 1 handbag, 1 dining table, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 stop sign, 2 umbrellas, 1 handbag, 1 dining table, 8.6ms\n",
      "Speed: 1.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 buss, 2 umbrellas, 1 handbag, 1 dining table, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 buss, 2 umbrellas, 2 handbags, 1 dining table, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 8.3ms\n",
      "Speed: 2.2ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 8.8ms\n",
      "Speed: 1.9ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 2 umbrellas, 1 handbag, 1 dining table, 7.6ms\n",
      "Speed: 1.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 buss, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.7ms\n",
      "Speed: 2.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 8.3ms\n",
      "Speed: 1.9ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.5ms\n",
      "Speed: 1.7ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 backpack, 2 umbrellas, 4 handbags, 1 dining table, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 1 backpack, 2 umbrellas, 4 handbags, 1 dining table, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 1 chair, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 5 handbags, 1 dining table, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 4 handbags, 1 dining table, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 5 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 2 umbrellas, 4 handbags, 1 dining table, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 train, 2 umbrellas, 2 handbags, 1 dining table, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 train, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 train, 1 stop sign, 2 umbrellas, 2 handbags, 1 dining table, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 2 umbrellas, 3 handbags, 1 dining table, 9.2ms\n",
      "Speed: 2.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 2 umbrellas, 3 handbags, 1 chair, 1 dining table, 9.4ms\n",
      "Speed: 2.2ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 1 handbag, 1 dining table, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 4 handbags, 1 chair, 1 dining table, 7.5ms\n",
      "Speed: 2.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 4 handbags, 1 chair, 1 dining table, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.9ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 2 handbags, 1 dining table, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 3 handbags, 1 dining table, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 1 chair, 1 dining table, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 1 handbag, 1 dining table, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 1 bus, 2 umbrellas, 1 handbag, 1 dining table, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 1 bus, 2 umbrellas, 1 dining table, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 1 handbag, 1 dining table, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 1 bus, 2 umbrellas, 1 dining table, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 bus, 2 umbrellas, 1 dining table, 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 bus, 1 backpack, 2 umbrellas, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 1 dining table, 8.7ms\n",
      "Speed: 2.0ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 1 dining table, 8.6ms\n",
      "Speed: 1.9ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 1 dining table, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 1 dining table, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 dining table, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 dining table, 7.4ms\n",
      "Speed: 2.0ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 dining table, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 dining table, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 2 handbags, 1 dining table, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 7.2ms\n",
      "Speed: 1.7ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 4 handbags, 1 dining table, 8.2ms\n",
      "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 5 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 4 handbags, 1 dining table, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 3 handbags, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 3 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 backpacks, 1 umbrella, 3 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 7.6ms\n",
      "Speed: 2.0ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 backpacks, 2 umbrellas, 4 handbags, 1 chair, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 5 handbags, 1 chair, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 2 handbags, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 backpacks, 2 umbrellas, 3 handbags, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 cars, 2 backpacks, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 car, 2 backpacks, 2 umbrellas, 4 handbags, 1 dining table, 8.3ms\n",
      "Speed: 1.9ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 backpacks, 2 umbrellas, 4 handbags, 1 dining table, 8.4ms\n",
      "Speed: 1.8ms preprocess, 8.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 backpacks, 2 umbrellas, 4 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 3 handbags, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 backpacks, 2 umbrellas, 4 handbags, 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 4 handbags, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 4 handbags, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 4 handbags, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 4 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 4 handbags, 1 dining table, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 3 handbags, 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 3 handbags, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 backpacks, 2 umbrellas, 4 handbags, 7.7ms\n",
      "Speed: 1.9ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 3 handbags, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 1 handbag, 7.5ms\n",
      "Speed: 2.3ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 7.7ms\n",
      "Speed: 1.9ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 backpacks, 2 umbrellas, 4 handbags, 1 dining table, 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 2 umbrellas, 4 handbags, 1 dining table, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 7.2ms\n",
      "Speed: 1.9ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 4 handbags, 1 dining table, 7.5ms\n",
      "Speed: 1.8ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 3 handbags, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 backpacks, 2 umbrellas, 1 handbag, 1 dining table, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 backpacks, 2 umbrellas, 1 handbag, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 dining table, 8.2ms\n",
      "Speed: 1.8ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 8.3ms\n",
      "Speed: 2.1ms preprocess, 8.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 truck, 1 backpack, 2 umbrellas, 1 handbag, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 truck, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 12.8ms\n",
      "Speed: 1.9ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 truck, 2 backpacks, 2 umbrellas, 1 handbag, 1 dining table, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 truck, 2 backpacks, 2 umbrellas, 1 handbag, 1 dining table, 8.7ms\n",
      "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 truck, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 truck, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 truck, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 truck, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.9ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 truck, 1 backpack, 2 umbrellas, 3 handbags, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 2 trucks, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 truck, 2 backpacks, 2 umbrellas, 2 handbags, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 truck, 2 umbrellas, 1 handbag, 1 chair, 1 dining table, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 2 umbrellas, 1 handbag, 7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 cars, 1 backpack, 2 umbrellas, 2 handbags, 1 dining table, 7.8ms\n",
      "Speed: 1.9ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 2 umbrellas, 2 handbags, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 1 handbag, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 2 handbags, 1 banana, 1 dining table, 7.8ms\n",
      "Speed: 1.9ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 3 handbags, 1 chair, 1 dining table, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 car, 2 umbrellas, 2 handbags, 1 dining table, 7.7ms\n",
      "Speed: 2.0ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 3 handbags, 1 dining table, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 3 handbags, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 3 handbags, 1 dining table, 7.6ms\n",
      "Speed: 1.6ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 2 umbrellas, 4 handbags, 1 keyboard, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 umbrellas, 4 handbags, 1 keyboard, 8.1ms\n",
      "Speed: 2.1ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 2 umbrellas, 3 handbags, 7.9ms\n",
      "Speed: 2.0ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 8.2ms\n",
      "Speed: 1.8ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 7.8ms\n",
      "Speed: 2.1ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 3 handbags, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 3 handbags, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 3 handbags, 1 dining table, 7.6ms\n",
      "Speed: 1.6ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 3 handbags, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 2 handbags, 1 chair, 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 2 handbags, 3 chairs, 1 dining table, 7.6ms\n",
      "Speed: 2.0ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 2 handbags, 1 dining table, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 dining table, 1 keyboard, 7.7ms\n",
      "Speed: 2.0ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 handbag, 1 dining table, 1 keyboard, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 handbag, 1 dining table, 7.4ms\n",
      "Speed: 2.0ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 2 handbags, 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 handbag, 12.9ms\n",
      "Speed: 1.9ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 handbag, 9.5ms\n",
      "Speed: 7.1ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 2 handbags, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 2 handbags, 1 chair, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 2 handbags, 2 chairs, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 2 handbags, 2 chairs, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 handbag, 1 chair, 7.5ms\n",
      "Speed: 1.7ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 2 handbags, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 handbag, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 handbag, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 backpack, 2 umbrellas, 1 handbag, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 handbag, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 handbag, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 1 handbag, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 1 keyboard, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 keyboard, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 2 umbrellas, 2 handbags, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 2 umbrellas, 2 handbags, 1 keyboard, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 2 umbrellas, 1 handbag, 8.4ms\n",
      "Speed: 1.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 2 handbags, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 2 umbrellas, 1 handbag, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 2 umbrellas, 2 handbags, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 2 handbags, 1 book, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 2 handbags, 1 chair, 7.7ms\n",
      "Speed: 2.2ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 3 handbags, 1 keyboard, 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 backpack, 2 umbrellas, 3 handbags, 1 keyboard, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 backpacks, 2 umbrellas, 3 handbags, 1 chair, 1 keyboard, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 backpack, 1 umbrella, 2 handbags, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 11.5ms\n",
      "Speed: 1.7ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 backpacks, 2 umbrellas, 2 handbags, 1 chair, 1 book, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 backpacks, 2 umbrellas, 2 handbags, 1 chair, 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 1 handbag, 1 chair, 1 book, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 2 umbrellas, 2 handbags, 1 chair, 1 book, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 1 handbag, 1 chair, 1 book, 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 8.3ms\n",
      "Speed: 1.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 handbag, 1 chair, 1 book, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 handbag, 1 chair, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 1 chair, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 1 chair, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 1 chair, 7.4ms\n",
      "Speed: 2.2ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 2 umbrellas, 1 chair, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 2 umbrellas, 1 chair, 1 book, 7.2ms\n",
      "Speed: 1.7ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 chair, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 2 umbrellas, 1 chair, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 2 chairs, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 stop sign, 2 umbrellas, 1 handbag, 3 chairs, 7.3ms\n",
      "Speed: 1.8ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 stop sign, 2 umbrellas, 2 chairs, 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 9.6ms\n",
      "Speed: 2.1ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 backpack, 2 umbrellas, 1 handbag, 2 chairs, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 backpack, 2 umbrellas, 1 chair, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 buss, 1 backpack, 2 umbrellas, 1 chair, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 buss, 1 truck, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 3 buss, 2 umbrellas, 2 handbags, 1 chair, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 buss, 2 umbrellas, 1 handbag, 2 chairs, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 backpack, 2 umbrellas, 1 chair, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 2 backpacks, 2 umbrellas, 1 chair, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 backpack, 2 umbrellas, 1 chair, 7.8ms\n",
      "Speed: 1.8ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 backpack, 2 umbrellas, 1 chair, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 buss, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 2 umbrellas, 1 handbag, 1 chair, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 buss, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 buss, 2 umbrellas, 1 handbag, 1 chair, 8.1ms\n",
      "Speed: 2.2ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 buss, 1 backpack, 2 umbrellas, 3 handbags, 1 chair, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 1 stop sign, 2 umbrellas, 3 handbags, 1 chair, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 3 handbags, 1 chair, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 1 handbag, 1 chair, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 3 handbags, 1 chair, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 8.8ms\n",
      "Speed: 1.4ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 2 backpacks, 2 umbrellas, 2 handbags, 1 chair, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 stop sign, 2 backpacks, 2 umbrellas, 3 handbags, 1 chair, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 2 backpacks, 2 umbrellas, 3 handbags, 1 chair, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 2 backpacks, 2 umbrellas, 3 handbags, 1 chair, 9.3ms\n",
      "Speed: 2.1ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 buss, 2 backpacks, 2 umbrellas, 2 handbags, 1 chair, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 1 umbrella, 2 handbags, 1 chair, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 buss, 1 backpack, 2 umbrellas, 3 handbags, 1 chair, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 2 umbrellas, 3 handbags, 1 chair, 8.4ms\n",
      "Speed: 1.7ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 8.1ms\n",
      "Speed: 1.9ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 stop sign, 2 umbrellas, 2 handbags, 1 chair, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 2 umbrellas, 5 handbags, 1 chair, 8.5ms\n",
      "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 2 handbags, 1 chair, 8.3ms\n",
      "Speed: 1.8ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 2 umbrellas, 3 handbags, 1 chair, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 2 handbags, 1 chair, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 8.2ms\n",
      "Speed: 1.9ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 2 backpacks, 2 umbrellas, 1 chair, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 handbag, 1 chair, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 chair, 8.6ms\n",
      "Speed: 2.2ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 1 stop sign, 1 backpack, 2 umbrellas, 1 chair, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 2 backpacks, 2 umbrellas, 1 handbag, 1 chair, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 2 backpacks, 2 umbrellas, 1 chair, 7.8ms\n",
      "Speed: 1.8ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 2 umbrellas, 1 chair, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bus, 1 backpack, 2 umbrellas, 1 chair, 8.5ms\n",
      "Speed: 1.9ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 1 handbag, 1 chair, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 2 umbrellas, 1 handbag, 1 chair, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 2 umbrellas, 1 handbag, 1 chair, 7.5ms\n",
      "Speed: 1.8ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 2 umbrellas, 2 chairs, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 7.6ms\n",
      "Speed: 1.8ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 1 bus, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 truck, 1 stop sign, 1 umbrella, 2 handbags, 1 chair, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 1 bus, 1 stop sign, 1 umbrella, 2 handbags, 1 chair, 8.4ms\n",
      "Speed: 1.9ms preprocess, 8.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 1 umbrella, 1 handbag, 1 chair, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 1 umbrella, 2 handbags, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 1 umbrella, 2 handbags, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 backpack, 1 umbrella, 2 handbags, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 umbrella, 2 handbags, 7.5ms\n",
      "Speed: 1.7ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 1 umbrella, 3 handbags, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 backpack, 1 umbrella, 2 handbags, 1 chair, 8.2ms\n",
      "Speed: 2.0ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 backpack, 1 umbrella, 1 handbag, 1 chair, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 1 umbrella, 1 handbag, 1 chair, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 backpack, 1 umbrella, 1 handbag, 2 chairs, 24.9ms\n",
      "Speed: 2.1ms preprocess, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 bus, 1 umbrella, 1 handbag, 1 chair, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 stop sign, 1 umbrella, 2 chairs, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 bus, 1 umbrella, 2 chairs, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 umbrella, 2 chairs, 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 1 backpack, 1 umbrella, 1 chair, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 1 backpack, 1 umbrella, 1 handbag, 1 chair, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 1 backpack, 1 umbrella, 1 handbag, 1 chair, 8.4ms\n",
      "Speed: 1.7ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 umbrella, 2 handbags, 1 chair, 7.6ms\n",
      "Speed: 1.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 umbrella, 2 handbags, 1 chair, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 2 umbrellas, 1 handbag, 1 chair, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 bus, 1 stop sign, 1 umbrella, 2 handbags, 1 chair, 8.4ms\n",
      "Speed: 1.8ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 car, 1 bus, 1 stop sign, 1 backpack, 1 umbrella, 1 chair, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 chair, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 2 chairs, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 2 chairs, 8.2ms\n",
      "Speed: 2.6ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 2 chairs, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 2 handbags, 2 chairs, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 2 chairs, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 2 chairs, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 car, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 2 chairs, 7.8ms\n",
      "Speed: 2.2ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 bus, 1 stop sign, 1 umbrella, 2 handbags, 2 chairs, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 2 chairs, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 2 chairs, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 2 buss, 1 stop sign, 1 umbrella, 3 handbags, 2 chairs, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 2 buss, 1 stop sign, 1 umbrella, 2 handbags, 2 chairs, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 2 buss, 1 stop sign, 1 umbrella, 1 handbag, 2 chairs, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 2 buss, 1 stop sign, 2 umbrellas, 2 chairs, 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 2 buss, 1 stop sign, 1 umbrella, 1 chair, 7.8ms\n",
      "Speed: 1.9ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 chair, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 chair, 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 chair, 7.8ms\n",
      "Speed: 1.8ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 chair, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 bus, 1 stop sign, 2 umbrellas, 1 chair, 7.8ms\n",
      "Speed: 1.9ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 car, 1 bus, 1 stop sign, 2 umbrellas, 1 chair, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 cars, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 umbrella, 1 chair, 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 stop sign, 1 umbrella, 1 chair, 9.2ms\n",
      "Speed: 2.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 bus, 1 stop sign, 1 umbrella, 1 handbag, 1 chair, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 umbrella, 1 handbag, 1 chair, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 umbrella, 1 chair, 9.6ms\n",
      "Speed: 2.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 bus, 1 umbrella, 1 chair, 9.6ms\n",
      "Speed: 2.1ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "def process_video_with_tracking(model, input_video_path, show_video=True, save_video=False, output_video_path=\"detect_output_video.mp4\"):\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Error: Could not open video file.\")\n",
    "    \n",
    "    # Get input video frame rate and dimensions\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define the output video writer\n",
    "    if save_video:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    color = (0, 0, 255)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        results = model(frame)\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "        cls = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "        confs = results[0].boxes.conf.cpu().numpy().astype(float)\n",
    "        \n",
    "        \n",
    "        for box, cl, conf in zip(boxes, cls, confs):\n",
    "            if cl == 0:\n",
    "                cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f\"Person: {conf:.2f}\",\n",
    "                    (box[0], box[1]),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0, 255, 255),\n",
    "                    2,\n",
    "                )\n",
    "        if save_video:\n",
    "            out.write(frame)\n",
    "            \n",
    "        if show_video:\n",
    "            frame = cv2.resize(frame, (0, 0), fx=0.75, fy=0.75)\n",
    "            cv2.imshow(\"frame\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    \n",
    "    # Release the input video capture and output video writer\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    \n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage:\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "model.fuse()\n",
    "process_video_with_tracking(model, \"crowd.mp4\", show_video=True, save_video=True, output_video_path=\"detect_output_video.mp4\")                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b00cfb",
   "metadata": {},
   "source": [
    "## Ğ¢Ñ€Ğ¸ĞºĞ¸Ğ½Ğ³ Ğ»ÑĞ´ĞµĞ¹, Ñƒ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¸Ğ· ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… ÑĞ²Ğ¾Ğ¹ Ñ†Ğ²ĞµÑ‚ Ğ² ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğ¸ Ğ¸Ñ… id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a1954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11s summary (fused): 100 layers, 9,443,760 parameters, 0 gradients, 21.5 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "def process_video_with_tracking(model, input_video_path, show_video=True, save_video=False, output_video_path=\"tracking_output_video.mp4\"):\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Error: Could not open video file.\")\n",
    "    \n",
    "    # Get input video frame rate and dimensions\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define the output video writer\n",
    "    if save_video:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # color = (255, 0, 0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        results = model.track(frame, iou=0.4, conf=0.5, persist=True, imgsz=640, verbose=False, tracker=\"botsort.yaml\")\n",
    "        \n",
    "        if results[0].boxes.id != None: # this will ensure that id is not None -> exist tracks\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "            ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "            cls = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "            confs = results[0].boxes.conf.cpu().numpy().astype(float)\n",
    "            \n",
    "            \n",
    "            for box, id, cl, conf in zip(boxes, ids, cls, confs):\n",
    "                if cl == 0:\n",
    "                    # Generate a random color for each object based on its ID\n",
    "                    random.seed(int(id))\n",
    "                    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "                    \n",
    "                    \n",
    "                    cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        f\"Person{id}: {conf:.2f}\",\n",
    "                        (box[0], box[1]),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5,\n",
    "                        (0, 255, 255),\n",
    "                        2,\n",
    "                    )\n",
    "        if save_video:\n",
    "            out.write(frame)\n",
    "            \n",
    "        if show_video:\n",
    "            frame = cv2.resize(frame, (0, 0), fx=0.75, fy=0.75)\n",
    "            cv2.imshow(\"frame\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    \n",
    "    # Release the input video capture and output video writer\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    \n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage:\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "model.fuse()\n",
    "process_video_with_tracking(model, \"crowd.mp4\", show_video=True, save_video=True, output_video_path=\"tracking_output_video.mp4\")                                         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
